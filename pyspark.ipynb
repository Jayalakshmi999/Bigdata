{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "22e60f05-cc4c-4d34-b5e7-2f7f53422d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000001DEAB1AE970>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.getOrCreate()\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d7e6cda3-d1eb-414c-ac40-d43c446b6689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[_c0: string, Title: string, Author: string, Score: string, Ratings: string, Published: string]\n",
      "DataFrame[_c0: string, Title: string, Genre: string]\n",
      "DataFrame[_c0: string, Title: string, Description: string]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col \n",
    "book_metadata= spark.read.format('csv').option('header','true').load('book_metadata.csv')\n",
    "book_genre= spark.read.format('csv').option('header','true').load('book_genres.csv')\n",
    "book_descriptions= spark.read.format('csv').option('header','true').load('book_descriptions.csv')\n",
    "\n",
    "\n",
    "book_metadata.createOrReplaceTempView('book_metadata_view')\n",
    "book_genre.createOrReplaceTempView('book_genre_view')\n",
    "book_descriptions.createOrReplaceTempView('book_descriptions_view')\n",
    "\n",
    "print(book_metadata)\n",
    "print(book_genre)\n",
    "print(book_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7586d2ce-1639-4d4b-ae11-7e12e80c9859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'> <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "+----+--------------------+--------------------+-----+-------+---------+--------------------+\n",
      "| _c0|               Title|              Author|Score|Ratings|Published|         Description|\n",
      "+----+--------------------+--------------------+-----+-------+---------+--------------------+\n",
      "|1542|Midnight Sun (The...|     Stephenie Meyer| 3.73| 223895|     2020|When Edward Culle...|\n",
      "| 784|   Out of the Corner|      Jennifer  Grey| 3.81|   8843|     2022|A deeply candid a...|\n",
      "|1662|               Fangs|      Sarah Andersen| 4.26|  36311|     2020|A love story betw...|\n",
      "|1141|    You Can Trust Me|    Kiersten Modglin| 4.09|   2232|     2023|For two happy cou...|\n",
      "|2550|Authentically Izz...|    Pepper D. Basham| 3.89|   2271|     2022|“Dear Izzy—I feel...|\n",
      "|2811|            Het plan|         Nando Boers| 4.16|     67|     2023|Het plan geeft de...|\n",
      "|2104|                Kala|         Colin Walsh| 4.17|    798|     2023|A gripping litera...|\n",
      "|3644|The Rebound (Look...|        Kendall Ryan| 4.07|   2903|     2021|A smokin\\' hot ne...|\n",
      "|2855|Confessions of an...|        Joya Goffney| 4.29|   4551|     2022|The second novel ...|\n",
      "|1215|Everything Happen...|         Kate Bowler|  3.8|  45308|     2018|A divinity profes...|\n",
      "|1783|    You, with a View|      Jessica  Joyce| 4.39|   4629|     2023|Two weeks on the ...|\n",
      "| 457|Dead Mercenary&#3...|      Simon W. Clark|  4.5|      2|     2023|The road to hell ...|\n",
      "| 933|Curvy Girls Can&#...|     Kelsie Stelting| 4.03|   7373|     2020|Curvy girls deser...|\n",
      "|3488|       Out on a Limb|  Hannah Bonam-Young| 4.52|   7059|     2023|Winnifred &quot;W...|\n",
      "|4401|Dragon&#39;s Temp...|        Lola Gabriel| 4.24|     78|     2023|My boss is a cree...|\n",
      "| 770|          The Centre|Ayesha Manazir Si...| 3.55|   1223|     2023|A darkly comic, b...|\n",
      "|4510|Surge (The Taking...|       Melissa  West| 3.72|     25|     2023|They’re running o...|\n",
      "|1866|Straight Dad (Fix...|     Raleigh Ruebins| 4.19|    531|     2023|Straight dads don...|\n",
      "| 294|Burn the Place: A...|        Iliana Regan| 3.64|   2801|     2019|A singular, power...|\n",
      "|2389|A Theatre for Dre...|        Polly Samson| 3.46|   4494|     2021|1960. The world i...|\n",
      "+----+--------------------+--------------------+-----+-------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result1 = book_metadata.join(book_descriptions, book_metadata['Title'] == book_descriptions['Title'], \"inner\").drop(book_descriptions['Title'],book_descriptions['_c0'])\n",
    "print(type(result1),type(book_metadata))\n",
    "result1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "38ce3c39-28a6-47ef-97d6-04f60445b9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[Title: string, Author: string, Score: string, Ratings: string, Published: string, Description: string, Genre: string]\n",
      "+--------------------+--------------------+-----+-------+---------+--------------------+--------------------+\n",
      "|               Title|              Author|Score|Ratings|Published|         Description|               Genre|\n",
      "+--------------------+--------------------+-----+-------+---------+--------------------+--------------------+\n",
      "|Midnight Sun (The...|     Stephenie Meyer| 3.73| 223895|     2020|When Edward Culle...|  Fantasy,Paranormal|\n",
      "|   Out of the Corner|      Jennifer  Grey| 3.81|   8843|     2022|A deeply candid a...|           Biography|\n",
      "|               Fangs|      Sarah Andersen| 4.26|  36311|     2020|A love story betw...|      Graphic Novels|\n",
      "|    You Can Trust Me|    Kiersten Modglin| 4.09|   2232|     2023|For two happy cou...|   Suspense,Thriller|\n",
      "|Authentically Izz...|    Pepper D. Basham| 3.89|   2271|     2022|“Dear Izzy—I feel...|           Christian|\n",
      "|            Het plan|         Nando Boers| 4.16|     67|     2023|Het plan geeft de...|              Sports|\n",
      "|                Kala|         Colin Walsh| 4.17|    798|     2023|A gripping litera...|Mystery,Suspense,...|\n",
      "|The Rebound (Look...|        Kendall Ryan| 4.07|   2903|     2021|A smokin\\' hot ne...|              Sports|\n",
      "|Confessions of an...|        Joya Goffney| 4.29|   4551|     2022|The second novel ...|            Religion|\n",
      "|Everything Happen...|         Kate Bowler|  3.8|  45308|     2018|A divinity profes...|Spirituality,Chri...|\n",
      "|    You, with a View|      Jessica  Joyce| 4.39|   4629|     2023|Two weeks on the ...|      Romance,Travel|\n",
      "|Dead Mercenary&#3...|      Simon W. Clark|  4.5|      2|     2023|The road to hell ...|      Suspense,Crime|\n",
      "|Curvy Girls Can&#...|     Kelsie Stelting| 4.03|   7373|     2020|Curvy girls deser...|    Sports,Chick Lit|\n",
      "|       Out on a Limb|  Hannah Bonam-Young| 4.52|   7059|     2023|Winnifred &quot;W...|Contemporary,Roma...|\n",
      "|Dragon&#39;s Temp...|        Lola Gabriel| 4.24|     78|     2023|My boss is a cree...|          Paranormal|\n",
      "|          The Centre|Ayesha Manazir Si...| 3.55|   1223|     2023|A darkly comic, b...|LGBT,Science Fict...|\n",
      "|Surge (The Taking...|       Melissa  West| 3.72|     25|     2023|They’re running o...|Science Fiction,Y...|\n",
      "|Straight Dad (Fix...|     Raleigh Ruebins| 4.19|    531|     2023|Straight dads don...|              Sports|\n",
      "|Burn the Place: A...|        Iliana Regan| 3.64|   2801|     2019|A singular, power...|           Cookbooks|\n",
      "|A Theatre for Dre...|        Polly Samson| 3.46|   4494|     2021|1960. The world i...|                 Art|\n",
      "+--------------------+--------------------+-----+-------+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result=result1.join(book_genre,result1['Title']==book_genre['Title'],\"inner\").drop(book_genre['Title'],book_genre['_c0'],result1['_c0'])\n",
    "print(result)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0bd8989a-9280-4985-bc96-7077b1e87085",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"results.csv\"\n",
    "\n",
    "\n",
    "# Write the DataFrame to a text file\n",
    "# Assuming result is your DataFrame\n",
    "result.coalesce(1).write.csv(output_path, header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ef36fa6a-10dd-4e27-81ff-bcf6dd98b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s556452\\big-data-venv\\lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:485: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if should_localize and is_datetime64tz_dtype(s.dtype) and s.dt.tz is not None:\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[UNSUPPORTED_DATA_TYPE_FOR_DATASOURCE] The Text datasource doesn't support the column `Score` of the type \"DOUBLE\".",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[144], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m text_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/s556452/Downloads/mapreduce-mvn-main/mapreduce-mvn-main/data/input/output.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Write the PySpark DataFrame to a text file\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mspark_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Stop the Spark session\u001b[39;00m\n\u001b[0;32m     31\u001b[0m spark\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[1;32m~\\big-data-venv\\lib\\site-packages\\pyspark\\sql\\readwriter.py:1774\u001b[0m, in \u001b[0;36mDataFrameWriter.text\u001b[1;34m(self, path, compression, lineSep)\u001b[0m\n\u001b[0;32m   1726\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Saves the content of the DataFrame in a text file at the specified path.\u001b[39;00m\n\u001b[0;32m   1727\u001b[0m \u001b[38;5;124;03mThe text files will be encoded as UTF-8.\u001b[39;00m\n\u001b[0;32m   1728\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1771\u001b[0m \u001b[38;5;124;03m+---------+\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1773\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression, lineSep\u001b[38;5;241m=\u001b[39mlineSep)\n\u001b[1;32m-> 1774\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\big-data-venv\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\big-data-venv\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [UNSUPPORTED_DATA_TYPE_FOR_DATASOURCE] The Text datasource doesn't support the column `Score` of the type \"DOUBLE\"."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Input CSV file path\n",
    "csv_file_path = \"results.csv/part-00000-74e6199a-f186-4b5c-b046-e10ecbd4aa32-c000.csv\"\n",
    "\n",
    "# Output text file path\n",
    "text_file_path = \"C:/Users/s556452/Downloads/mapreduce-mvn-main/mapreduce-mvn-main/data/input/output.txt\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"CSVtoText\").getOrCreate()\n",
    "\n",
    "# Replace 'your_input.csv' with the path to your CSV file\n",
    "csv_file_path = \"results.csv/part-00000-4b173e62-f130-4b3a-bd00-40318816976a-c000.csv\"\n",
    "\n",
    "# Read CSV file into a Pandas DataFrame\n",
    "pandas_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Convert Pandas DataFrame to PySpark DataFrame\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "\n",
    "# Replace 'your_output.txt' with the desired path for the text file\n",
    "text_file_path = \"C:/Users/s556452/Downloads/mapreduce-mvn-main/mapreduce-mvn-main/data/input/output.txt\"\n",
    "\n",
    "# Write the PySpark DataFrame to a text file\n",
    "spark_df.write.text(text_file_path)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0ee5200b-c133-4e89-9139-916910fdc5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Title', 'Author', 'Score', 'Ratings', 'Published', 'Description', 'Genre', 'all_columns']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ConvertToText\").getOrCreate()\n",
    "\n",
    "# Sample DataFrame\n",
    "df= spark.read.format('csv').option('header','true').load('results.csv/part-00000-4b173e62-f130-4b3a-bd00-40318816976a-c000.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Convert Score, Ratings, and Published to STRING\n",
    "df = df.withColumn(\"Score\", F.col(\"Score\").cast(\"string\"))\n",
    "df = df.withColumn(\"Ratings\", F.col(\"Ratings\").cast(\"string\"))\n",
    "df = df.withColumn(\"Published\", F.col(\"Published\").cast(\"string\"))\n",
    "\n",
    "\n",
    "\n",
    "df = df.withColumn(\"all_columns\", F.concat_ws(\"\\t\", *df.columns))\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "# # Specify the path to the output text file\n",
    "output_path = \"C:/Users/s556452/Downloads/mapreduce-mvn-main/mapreduce-mvn-main/data/input/output.txt\"\n",
    "\n",
    "# Write DataFrame to a text file\n",
    "df.select(\"all_columns\").write.text(output_path)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e20da8c-ddbd-40ec-9963-1859ee03afa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
